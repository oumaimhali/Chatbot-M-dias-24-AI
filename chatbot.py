import streamlit as st
import openai
from openai import OpenAI
import requests
import json
import urllib3
from datetime import datetime
import re
from typing import List, Dict
from collections import defaultdict

# Configuration de la page Streamlit
st.set_page_config(page_title="Assistant M√©dias 24", page_icon="üóûÔ∏è", layout="wide")

# Configuration des cl√©s API
if 'OPENAI_API_KEY' not in st.secrets:
    st.error("Veuillez configurer votre cl√© API OpenAI dans les secrets Streamlit.")
    st.stop()

# Configuration d'OpenAI
client = OpenAI(api_key=st.secrets['OPENAI_API_KEY'])

# Configuration Elasticsearch
ES_URL = st.secrets.get('ELK_ENDPOINT', 'http://esmedias24.cloud.atlashoster.net:9200/')
ES_INDEX = st.secrets.get('ELK_INDEX', 'idxfnl')
ES_USERNAME = st.secrets.get('ELK_USERNAME', 'elastic')
ES_PASSWORD = st.secrets.get('ELK_PASSWORD', '')

if not ES_PASSWORD:
    st.error("Veuillez configurer les param√®tres Elasticsearch dans les secrets Streamlit.")
    st.stop()

# Configuration de l'authentification Elasticsearch
ES_AUTH = (ES_USERNAME, ES_PASSWORD)
ES_TIMEOUT = 30  # Timeout en secondes

# D√©sactiver les avertissements SSL
urllib3.disable_warnings()

def test_elasticsearch_connection():
    """Test la connexion √† Elasticsearch"""
    try:
        response = requests.get(
            ES_URL,
            auth=ES_AUTH,
            verify=False,
            timeout=ES_TIMEOUT
        )
        if response.ok:
            st.success("‚úÖ Connexion √† Elasticsearch √©tablie")
            return True
        else:
            st.error(f"‚ùå Erreur de connexion √† Elasticsearch: {response.text}")
            return False
    except requests.exceptions.ConnectTimeout:
        st.error("‚ùå D√©lai d'attente d√©pass√© lors de la connexion √† Elasticsearch")
        return False
    except requests.exceptions.ConnectionError:
        st.error("‚ùå Impossible de se connecter au serveur Elasticsearch")
        return False
    except Exception as e:
        st.error(f"‚ùå Erreur inattendue: {str(e)}")
        return False

def extract_keywords(query: str) -> List[str]:
    """Extrait les mots-cl√©s importants de la requ√™te"""
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": "Extrais les mots-cl√©s importants de cette requ√™te, en les s√©parant par des virgules. "
                              "Inclus les noms propres, les dates, les lieux et les concepts importants."
                },
                {"role": "user", "content": query}
            ],
            temperature=0.3,
            max_tokens=100
        )
        keywords = response.choices[0].message.content.split(',')
        return [k.strip() for k in keywords if k.strip()]
    except Exception as e:
        st.warning(f"Erreur lors de l'extraction des mots-cl√©s: {str(e)}")
        return [query]

def search_articles(query: str, size: int = 10) -> List[Dict]:
    """Recherche avanc√©e des articles dans Elasticsearch"""
    if not test_elasticsearch_connection():
        return []

    keywords = extract_keywords(query)
    
    search_body = {
        "query": {
            "bool": {
                "should": [
                    {"match_phrase": {"post_title": {"query": kw, "boost": 4}}} for kw in keywords
                ] + [
                    {"match_phrase": {"summary": {"query": kw, "boost": 3}}} for kw in keywords
                ],
                "minimum_should_match": 1
            }
        },
        "size": size,
        "_source": ["post_title", "summary", "lien1", "date"],
        "sort": [
            {"_score": "desc"},
            {"date": "desc"}
        ]
    }
    
    try:
        response = requests.post(
            f"{ES_URL}/{ES_INDEX}/_search",
            auth=ES_AUTH,
            json=search_body,
            verify=False,
            timeout=ES_TIMEOUT,
            headers={"Content-Type": "application/json"}
        )
        
        if response.ok:
            results = response.json()
            articles = []
            
            for hit in results.get("hits", {}).get("hits", []):
                source = hit.get("_source", {})
                articles.append({
                    "title": source.get("post_title", ""),
                    "content": source.get("summary", ""),
                    "url": source.get("lien1", ""),
                    "published_at": source.get("date", ""),
                    "score": hit.get("_score", 0)
                })
            
            if not articles:
                st.warning("Aucun article trouv√© pour cette requ√™te.")
            else:
                st.success(f"{len(articles)} articles trouv√©s")
            
            return articles
        else:
            st.error(f"Erreur Elasticsearch: {response.text}")
            return []
            
    except requests.exceptions.ConnectTimeout:
        st.error("D√©lai d'attente d√©pass√© lors de la recherche. Veuillez r√©essayer.")
        return []
    except requests.exceptions.ConnectionError:
        st.error("Impossible de se connecter au serveur Elasticsearch. Veuillez v√©rifier votre connexion.")
        return []
    except Exception as e:
        st.error(f"Erreur lors de la recherche: {str(e)}")
        return []

def analyze_articles(articles: List[Dict]) -> Dict:
    """Analyse les articles pour extraire des informations cl√©s"""
    analysis = {
        "timeline": defaultdict(list),
        "key_topics": defaultdict(int),
        "sources": set(),
        "date_range": {"start": None, "end": None}
    }
    
    for article in articles:
        # Timeline
        date = article.get("published_at", "").split("T")[0]
        if date:
            analysis["timeline"][date].append(article)
        
        # Sources
        if article.get("url"):
            analysis["sources"].add(article["url"])
        
        # Update date range
        if date:
            if not analysis["date_range"]["start"] or date < analysis["date_range"]["start"]:
                analysis["date_range"]["start"] = date
            if not analysis["date_range"]["end"] or date > analysis["date_range"]["end"]:
                analysis["date_range"]["end"] = date
    
    return analysis

def get_ai_response(query: str, articles: List[Dict]) -> str:
    """G√©n√®re une r√©ponse bas√©e sur les articles trouv√©s"""
    try:
        # Pr√©paration du contexte
        context = "Voici les articles pertinents trouv√©s :\n\n"
        for i, article in enumerate(articles, 1):
            title = article.get('title', 'Sans titre')
            content = article.get('content', '')
            date = article.get('date', '')
            context += f"Article {i}:\nTitre: {title}\nDate: {date}\nContenu: {content}\n\n"

        # Instruction pour le mod√®le
        system_prompt = """Tu es un assistant sp√©cialis√© dans l'analyse d'articles de M√©dias24. 
        Utilise les articles fournis pour r√©pondre aux questions de mani√®re pr√©cise et structur√©e.
        Si une chronologie est demand√©e, pr√©sente les √©v√©nements de mani√®re chronologique.
        Cite toujours tes sources en r√©f√©ren√ßant les articles.
        Si tu ne trouves pas l'information dans les articles fournis, dis-le clairement."""

        # Appel √† l'API OpenAI
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"Question: {query}\n\nContexte: {context}"}
            ],
            temperature=0.7,
            max_tokens=1000
        )

        # Extraction de la r√©ponse
        return response.choices[0].message.content

    except Exception as e:
        st.error(f"Erreur lors de la g√©n√©ration de la r√©ponse : {str(e)}")
        return "D√©sol√©, je n'ai pas pu g√©n√©rer une r√©ponse. Veuillez r√©essayer."

# Interface Streamlit
st.title("Assistant M√©dias 24 ")
st.markdown("""
### Un assistant intelligent sp√©cialis√© dans l'actualit√© marocaine

Je peux vous aider √† :
- Analyser en profondeur les sujets d'actualit√©
- Cr√©er des chronologies d√©taill√©es des √©v√©nements
- Identifier les tendances et d√©veloppements cl√©s
- Fournir des analyses contextuelles approfondies
""")

# Zone de saisie utilisateur
query = st.text_input("Posez votre question ou indiquez le sujet qui vous int√©resse :")

# Param√®tres de recherche
col1, col2 = st.columns(2)
with col1:
    max_results = st.slider("Nombre d'articles √† analyser", min_value=5, max_value=50, value=20)
with col2:
    sort_by = st.selectbox(
        "Trier les r√©sultats par",
        ["Pertinence et date", "Date uniquement", "Pertinence uniquement"]
    )

if query:
    with st.spinner(" Recherche et analyse approfondie en cours..."):
        # Recherche des articles
        articles = search_articles(query, size=max_results)
        
        if articles:
            # Tri des articles selon le choix de l'utilisateur
            if sort_by == "Date uniquement":
                articles.sort(key=lambda x: x["published_at"], reverse=True)
            elif sort_by == "Pertinence uniquement":
                articles.sort(key=lambda x: x["score"], reverse=True)
            
            # Afficher la r√©ponse g√©n√©r√©e
            response = get_ai_response(query, articles)
            st.markdown(response)
            
            # Afficher les sources
            with st.expander("Consulter les articles sources"):
                for article in articles:
                    st.markdown(f"""
                    **{article['published_at'].split('T')[0]}** - [{article['title']}]({article['url']})  
                    {article['content'][:200]}...
                    """)
        else:
            st.warning("Aucun article trouv√© pour cette requ√™te.")
