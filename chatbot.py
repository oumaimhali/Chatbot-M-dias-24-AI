import streamlit as st
import openai
from openai import OpenAI
import requests
import json
import urllib3
from datetime import datetime
import re
from typing import List, Dict
from collections import defaultdict

# Configuration de la page Streamlit (doit √™tre en premier)
st.set_page_config(page_title="Assistant M√©dias 24", page_icon="üóûÔ∏è", layout="wide")

# D√©sactiver les avertissements SSL
urllib3.disable_warnings()

# Configuration
ES_URL = "https://esmedias24.cloud.atlashoster.net:9200"  # Chang√© pour HTTPS
ES_INDEX = "idxfnl"
ES_AUTH = ("elastic", "Zo501nQV7AKxxxxxx")
ES_TIMEOUT = 30  # Timeout en secondes

# Configuration OpenAI
try:
    api_key = st.secrets["OPENAI_API_KEY"]
    client = OpenAI(api_key=api_key)
except Exception as e:
    st.error(f"Erreur de configuration: {str(e)}")
    st.error("Veuillez configurer votre cl√© API dans .streamlit/secrets.toml")

def test_elasticsearch_connection():
    """Test la connexion √† Elasticsearch"""
    try:
        response = requests.get(
            ES_URL,
            auth=ES_AUTH,
            verify=False,
            timeout=ES_TIMEOUT
        )
        if response.ok:
            st.success("‚úÖ Connexion √† Elasticsearch √©tablie")
            return True
        else:
            st.error(f"‚ùå Erreur de connexion √† Elasticsearch: {response.text}")
            return False
    except requests.exceptions.ConnectTimeout:
        st.error("‚ùå D√©lai d'attente d√©pass√© lors de la connexion √† Elasticsearch")
        return False
    except requests.exceptions.ConnectionError:
        st.error("‚ùå Impossible de se connecter au serveur Elasticsearch")
        return False
    except Exception as e:
        st.error(f"‚ùå Erreur inattendue: {str(e)}")
        return False

def extract_keywords(query: str) -> List[str]:
    """Extrait les mots-cl√©s importants de la requ√™te"""
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": "Extrais les mots-cl√©s importants de cette requ√™te, en les s√©parant par des virgules. "
                              "Inclus les noms propres, les dates, les lieux et les concepts importants."
                },
                {"role": "user", "content": query}
            ],
            temperature=0.3,
            max_tokens=100
        )
        keywords = response.choices[0].message.content.split(',')
        return [k.strip() for k in keywords if k.strip()]
    except Exception as e:
        st.warning(f"Erreur lors de l'extraction des mots-cl√©s: {str(e)}")
        return [query]

def search_articles(query: str, size: int = 10) -> List[Dict]:
    """Recherche avanc√©e des articles dans Elasticsearch"""
    if not test_elasticsearch_connection():
        return []

    keywords = extract_keywords(query)
    
    search_body = {
        "query": {
            "bool": {
                "should": [
                    {"match_phrase": {"post_title": {"query": kw, "boost": 4}}} for kw in keywords
                ] + [
                    {"match_phrase": {"summary": {"query": kw, "boost": 3}}} for kw in keywords
                ],
                "minimum_should_match": 1
            }
        },
        "size": size,
        "_source": ["post_title", "summary", "lien1", "date"],
        "sort": [
            {"_score": "desc"},
            {"date": "desc"}
        ]
    }
    
    try:
        response = requests.post(
            f"{ES_URL}/{ES_INDEX}/_search",
            auth=ES_AUTH,
            json=search_body,
            verify=False,
            timeout=ES_TIMEOUT,
            headers={"Content-Type": "application/json"}
        )
        
        if response.ok:
            results = response.json()
            articles = []
            
            for hit in results.get("hits", {}).get("hits", []):
                source = hit.get("_source", {})
                articles.append({
                    "title": source.get("post_title", ""),
                    "content": source.get("summary", ""),
                    "url": source.get("lien1", ""),
                    "published_at": source.get("date", ""),
                    "score": hit.get("_score", 0)
                })
            
            if not articles:
                st.warning("Aucun article trouv√© pour cette requ√™te.")
            else:
                st.success(f"{len(articles)} articles trouv√©s")
            
            return articles
        else:
            st.error(f"Erreur Elasticsearch: {response.text}")
            return []
            
    except requests.exceptions.ConnectTimeout:
        st.error("D√©lai d'attente d√©pass√© lors de la recherche. Veuillez r√©essayer.")
        return []
    except requests.exceptions.ConnectionError:
        st.error("Impossible de se connecter au serveur Elasticsearch. Veuillez v√©rifier votre connexion.")
        return []
    except Exception as e:
        st.error(f"Erreur lors de la recherche: {str(e)}")
        return []

def analyze_articles(articles: List[Dict]) -> Dict:
    """Analyse les articles pour extraire des informations cl√©s"""
    analysis = {
        "timeline": defaultdict(list),
        "key_topics": defaultdict(int),
        "sources": set(),
        "date_range": {"start": None, "end": None}
    }
    
    for article in articles:
        # Timeline
        date = article.get("published_at", "").split("T")[0]
        if date:
            analysis["timeline"][date].append(article)
        
        # Sources
        if article.get("url"):
            analysis["sources"].add(article["url"])
        
        # Update date range
        if date:
            if not analysis["date_range"]["start"] or date < analysis["date_range"]["start"]:
                analysis["date_range"]["start"] = date
            if not analysis["date_range"]["end"] or date > analysis["date_range"]["end"]:
                analysis["date_range"]["end"] = date
    
    return analysis

def get_ai_response(query: str, articles: List[Dict]) -> str:
    """G√©n√®re une r√©ponse d√©taill√©e et structur√©e"""
    if not articles:
        return "Je n'ai pas trouv√© d'articles pertinents pour r√©pondre √† votre question."
    
    try:
        # Analyse des articles
        analysis = analyze_articles(articles)
        
        # Cr√©ation du contexte
        context = f"""Informations sur les articles trouv√©s:
1. P√©riode couverte: du {analysis['date_range']['start']} au {analysis['date_range']['end']}
2. Nombre d'articles: {len(articles)}
3. Sources: {len(analysis['sources'])} articles uniques

Articles par ordre chronologique:
"""
        
        for date, date_articles in sorted(analysis["timeline"].items()):
            context += f"\n{date}:\n"
            for article in date_articles:
                context += f"- {article['title']}\n"
                context += f"  {article['content'][:200]}...\n"

        messages = [
            {
                "role": "system",
                "content": """Tu es l'Assistant M√©dias 24, un expert en analyse d'actualit√©s marocaines.
                Ton objectif est de fournir des r√©ponses d√©taill√©es, pr√©cises et bien structur√©es.
                
                Directives pour tes r√©ponses:
                1. Commence par un bref r√©sum√© de la situation
                2. Pr√©sente les √©v√©nements de mani√®re chronologique
                3. Mets en √©vidence les dates et faits importants
                4. Identifie les tendances et d√©veloppements cl√©s
                5. Fournis une analyse approfondie
                6. Cite tes sources avec pr√©cision
                7. Conclus avec une synth√®se globale
                
                Format de r√©ponse:
                R√©sum√©
                Chronologie des √©v√©nements
                Points cl√©s
                Analyse
                Sources
                """
            },
            {
                "role": "user",
                "content": f"Question: {query}\n\nContexte:\n{context}"
            }
        ]

        response = client.chat.completions.create(
            model="gpt-3.5-turbo-16k",
            messages=messages,
            temperature=0.7,
            max_tokens=2000
        )
        
        return response.choices[0].message.content

    except Exception as e:
        st.error(f"Erreur lors de la g√©n√©ration de la r√©ponse: {str(e)}")
        return "D√©sol√©, je ne peux pas g√©n√©rer une r√©ponse pour le moment."

# Interface Streamlit
st.title("Assistant M√©dias 24 ")
st.markdown("""
### Un assistant intelligent sp√©cialis√© dans l'actualit√© marocaine

Je peux vous aider √† :
- Analyser en profondeur les sujets d'actualit√©
- Cr√©er des chronologies d√©taill√©es des √©v√©nements
- Identifier les tendances et d√©veloppements cl√©s
- Fournir des analyses contextuelles approfondies
""")

# Zone de saisie utilisateur
query = st.text_input("Posez votre question ou indiquez le sujet qui vous int√©resse :")

# Param√®tres de recherche
col1, col2 = st.columns(2)
with col1:
    max_results = st.slider("Nombre d'articles √† analyser", min_value=5, max_value=50, value=20)
with col2:
    sort_by = st.selectbox(
        "Trier les r√©sultats par",
        ["Pertinence et date", "Date uniquement", "Pertinence uniquement"]
    )

if query:
    with st.spinner(" Recherche et analyse approfondie en cours..."):
        # Recherche des articles
        articles = search_articles(query, size=max_results)
        
        if articles:
            # Tri des articles selon le choix de l'utilisateur
            if sort_by == "Date uniquement":
                articles.sort(key=lambda x: x["published_at"], reverse=True)
            elif sort_by == "Pertinence uniquement":
                articles.sort(key=lambda x: x["score"], reverse=True)
            
            # Afficher la r√©ponse g√©n√©r√©e
            response = get_ai_response(query, articles)
            st.markdown(response)
            
            # Afficher les sources
            with st.expander("Consulter les articles sources"):
                for article in articles:
                    st.markdown(f"""
                    **{article['published_at'].split('T')[0]}** - [{article['title']}]({article['url']})  
                    {article['content'][:200]}...
                    """)
        else:
            st.warning("Aucun article trouv√© pour cette requ√™te.")
